% This is part of the stat-toolkit documentation
% Copyright (C) 2012 Krzysztof Stachowiak
% See the file FDL for copying conditions.

\documentclass{report}

\begin{document}

\title{The statistical toolkit documentation/manual}
\author{Krzysztof Stachowiak}
\date{\today}

\maketitle

\tableofcontents

\section*{License note}
This is part of the stat-toolkit documentation.\\
Copyright (C) 2012 Krzysztof Stachowiak\\
See the file FDL for copying conditions.

\chapter{Libraries}

\section{Overview}
The libraries, which in this suite take a form of autonomous and atomic C++
header files are the foundation of the entire system. In many cases they are
uniquely tied to one of the command line tools, but others are shared between
the programs. Regardles of the particular use in the suite they are designed to
be as generic as possible and enable potiential use outside of the toolkit.
Therefore their interdependencies are minimized so that in many cases a
particular header file may be simply copied and pasted in another
project\footnote{Note however, that most of them still depends on some of the boost
libraries, so the point is not that they are lightweight, but that they may be
used separately.}.

\section{\texttt{aggr.h}}

	\subsection{Summary}
	The \texttt{aggr.h} library provides a set of classes for aggregating data.
	All onf its contents are enclosed within the \texttt{aggr} namespace. The
	aggregation classes are derived from an abstract class \texttt{aggregator}
	which defines the concept of an aggregator. The interface is simple and
	consists of two functions: \texttt{put} and \texttt{get}.

	\begin{itemize}
		\item \texttt{put(value : double) : void}\\
			This function allows storing a value in the aggregator.
		\item \texttt{get() : double}\\
			This function returns a value that is the result of the
			underlying agregation.
	\end{itemize}

	The input values aren't stored as in case of large data sets it could drain the
	available memory and is not really necessary. Therefore the \texttt{get}
	function may be called at any time as the aggregators are designed to compute
	their results dynamically. 

	\paragraph{Note}
	A convenient typedef has been placed in the \texttt{aggr} namespace to ease
	defining types based on an abstract pointer to an aggregator:\\
	\texttt{typedef unique\_ptr<aggregator> ptr;}

	\subsubsection{Available aggregators}
	There is a set of basic classes that the library provides:

	\begin{itemize}
		\item \texttt{count} - Counts the elements that are put into the aggregator.
		\item \texttt{sum} - Sums the elements that are put into the aggregator.
		\item \texttt{mean} - Computes the mean value of the input values.
		\item \texttt{stdev} - Computes the standard deviation of the input values.
		\item \texttt{ci\_gauss} - Computes the width of the confidence
			interval defined based on the input data and a predefined
			confidence levelm, assuming normal distribution.
	\end{itemize}

	\subsubsection{Uniform aggregators construction}
	All the aggregators can be instantiated uniformly with use of the function:
	\texttt{create\_from\_string(str : string) : unique\_ptr<aggregator>}.
	It is used by all the command line tools that accept the aggregator definitions
	from the command line arguments. The format for the string constructing an
	aggregator is:
	\begin{center}
		\texttt{\textit{aggregator-name} [\texttt{aggregator-argument-list}]}
	\end{center}
	The function will throw a string object upon receiving an unrecognized constructor
	string.

	The aggregator names are the same as the names of the respective classes. Currently
	only one of the aggregators requires an argument, which is the \texttt{ci\_gauss}
	expecting a single argument - the confidence level.

\section{aggr\_array.h}

	\subsection{Summary}
	The \texttt{aggr\_array.h} library provides means of defining a multidimensional
	array of aggregators. This library is a core for the pivot table generation tool
	but may be generalized to an arbitrary number of dimensions.

	The foundation of the library is an object of the class \texttt{array}, which is
	initialized with a list of dimensions and a list of the aggregator definitions.
	The dimension definition is a list of indices defining the columns which will
	form the given dimension. By the columns forming a dimension we mean that in the
	resumting array, all the values in the given dimension will come from the input
	rows having the same values in the forming columns. The aggregator definitions
	consist of pairs of the form: column index, aggregator constructor. The
	aggregators used in this library are taken from the \texttt{aggr.h} library.
	Therefore an aggregator assigned to a given column will be collecting the values
	from the input rows from the column. This way many aggregators may draw the input
	values from the same input column.

	The core class exposes two methods: \texttt{consume\_row} and
	\texttt{for\_each\_aggr}:
	
	\begin{itemize}
		\item \texttt{consume\_row(row : vector<string>, col\_mapped : bool,
			column\_map : map<uint32\_t, string>) : void}\\
			This method accepts a data row, which is its first argument.
			Note that the dimensions and aggregators are tied to the input
			data columns by their indices, however one may request the
			result to be displayed with use of the columns' headers. If
			such are provided (e.g. in the first row of the data stream),
			they must be given to this method. In such case the 
			\texttt{col\_mapped} flag must be set to \texttt{true}, and
			the \texttt{column\_map} argument must provide an appropriate
			mapping. If the column names are irrelevant, the \texttt{false}
			flag must be passed, and then the last argument will be ignored.
		\item \texttt{for\_each\_aggr(f : function<void(position, name, value)>) :
				void}\\
			This method will iterate over all the dimensions and all the
			aggregators for each point in the array (note that it may be
			given by multiple coordinates), and will call the provided
			function with appropriate arguments for each of the aggregators.
			The arguments are, respectively, the point's position, the
			aggregator's name and the aggregator's result value. The position
			object encapsulates a list of the coordinates, each of which
			consists of the list of pairs: column index, value at the column.
			This indicates that at the given coordinate all the values were
			taken from the input rows which had given values at the given
			columns. The following section gives more detail about the
			definition of the positions and the coordinates.
	\end{itemize}

	\subsection{Helper classes: \texttt{position} and \texttt{coordinate}}
	The aggregators array places the aggregators at the given coordinates, hence the
	``array'' name. The positions are given by sets of coordinates, and each of the
	coordinates defines the values that are expected at the given columns. Therefore
	the classes are defined as follows:

	\subsubsection{position}
	The position class is completely defined by a list of coordinates and is created
	based on such a list. Its public interface enables accessing a coordinate at a
	given index and the retrieval of a string representation of the position.

	\subsubsection{coord}
	The coordinate object is defined by a map associating column indices with the
	values that have been observed at the given index in the input data. Therefore
	saying that the given input row is at the given coordinate (note that the position
	may be given by multiple coordinates), means that for each of the map entry, the
	given row had a given value at the column given by the key. Also in the resulting
	table the aggregator at the given coordinate could have only been fed with values
	from the input rows at the coordinate (by the definifion of the input row's
	coordinate given above).

	Based on the above it may be said that an aggregator at a given position was only
	fed with the values from the input rows that satisfy the conditions of beeing at
	all the coordinates given by the position.

\chapter{Command Line Interface tools}

\section{\texttt{histogram}}

	\subsection{All options}
	\begin{itemize}
		\item \texttt{-d} \textit{delimiter} -- Allows selection of a custom
			delimiter for the output data.
		\item \texttt{-w} \textit{bucket-width} -- Determines the width of the
			histogram bucket. The default value is 1.0.
	\end{itemize}

	\subsection{Summary}
	The program takes a list of numbers, one number per line and builds
	a histogram of the provided distribution. The default bucket width is 1.0,
	but this setting may be overriden with use of the \texttt{-w \textit{width}}
	option.

	The output consists of two columns. The first column is built of the bucket
	center values, whereas in the second columnt the number of the results that
	fell into the according bucket is given. By default the columns are separated
	with the tab character, but this behavior can be altered with use of the
	\texttt{-d \textit{delimiter}} option.

	The program automatically generates empty buckets for the ranges, for which
	there were no results, therefore the data is ready for further processing.

\section{\texttt{aggr}}

	\subsection{Summary}
	This trivial tool accepts a list of numbers at its standard input and performs 
	one of the basic aggregations. The aggregator is shosen by the one and only
	command line argument, which is the aggregator construction string. For the
	details on the available aggregators and their respective construction strings
	see the manual for the \texttt{aggr.h} library.

\section{\texttt{groupby}}

	\subsection{All options}
	\begin{itemize}
		\item \texttt{-a} \textit{constr-string} -- defines an aggregator with a
			so called construction string.
		\item \texttt{-d} \textit{delim-char} -- defines a custom delimiter.
			The default value is the tab character.
		\item \texttt{-g} \textit{group-index} -- defines a groupping criterion.
	\end{itemize}

	\subsection{Summary}
	The program performs SQL-like groupping aggregation of a set of data given by a
	stream of tabuarized textual data.

	A stream of data rows separated with a linebreak is expected. The default
	field separator is the tab character, but may be altered with the
	\texttt{-d \textit{delimiter}} option. The output is defined by two sets
	of the data processing elments: the groupping criteria and the aggregators.
	It is required that there is at least one groupping criterion and at least one
	aggregator defined in the command line. Note that they will appear in the output
	in the same order in which they're given in the command line.

	\subsubsection{Groupping criteria}
	The grouppers are equivalent to the SQL's ``group by'' statements.
	Assumed that we have selected a set of grouppers for fields f1, f2, etc.,
	All the input data rows that have the same values in these fields will be
	considered groupped. We will be furhter saying they belong to a single group.
	The fields are given by indices; in order to define a groupping criterion we use
	a \texttt{-g \textit{column-index}} option.

	\subsubsection{Aggregators}
	The aggregators define the way in which given values for the specific fields
	are to be put together. Defining an aggregator consists in providing a
	\texttt{-a "\textit{field-index} \textit{aggr-constr}"} option, where the
	\textit{field-index} indicates the field that is to be aggregated by the
	current aggregator and \textit{aggr-constr} means the string constructing
	a given aggregator. The field index is a non-negative, zero-based index
	of a particular column, and the constructor string is the name of the
	aggregator followed by optional, aggregator-specific arguments. For details see
	the aggregator construction in the manual for the \texttt{aggr.h} library.

	For example in order to define an aggregator for the field 3 that will compute
	the gaussion confidence interval at the confidence level of 0.95 the argument
	line should be:

	\texttt{... | ./groupby ... -a "3 ci\_gauss 0.95" ...}

	\subsubsection{Output format}
	Let's assume that fields \texttt{f1, f2, ...} have been chosen as the
	grouppers and aggregators \texttt{a1, a2, ...} have been selected.
	The results will take the following form:
	\begin{verbatim}
	f1 f2 ... a1 a2 ...
	i1 i2 ... v1 v2 ...
	i3 i4 ... v3 v4 ...
	\end{verbatim}

	... where \texttt{i1, i2, ...} -- the "indicators" -- are the labels for
	the given fields that have been captured and \texttt{v1, v2, ...} are
	the computed aggregated values.

	\subsection{Examples}
	Let's consider a simple dataset:
	\begin{verbatim}
	$cat data
	50	4	1.0	2.0
	50	4	3.0	4.0
	50	6	1.0	2.0
	50	6	3.0	4.0
	100	4	1.0	2.0
	100	4	3.0	4.0
	100	6	1.0	2.0
	100	6	3.0	4.0
	\end{verbatim}

	Let's now take a look at different results depending on the input options.

	\begin{verbatim}
	$cat data | ./groupby -g1 -a "2 sum"
	1	"2 sum"
	4	8
	6	8
	\end{verbatim}

	\begin{verbatim}
	$cat data | ./groupby -g0 -g1 -a "2 sum" -a "3 mean"
	0	1	"2 sum"	"3 mean"
	50	4	4	3
	50	6	4	3
	100	4	4	3
	100	6	4	3
	\end{verbatim}

	\begin{verbatim}
	$cat data | ./groupby -g1 -g0 -a "2 sum" -a "3 mean"
	1	0	"2 sum"	"3 mean"
	4	50	4	3
	6	50	4	3
	4	100	4	3
	6	100	4	3
	\end{verbatim}

	\begin{verbatim}
	$cat data | ./groupby -g1 -g0 -a "3 mean" -a "2 sum"
	1	0	"3 mean"	"2 sum"
	4	50	3	4
	6	50	3	4
	4	100	3	4
	6	100	3	4
	\end{verbatim}

\section{\texttt{pivot}}

	\subsection{Summary}
	This program performs a pivot table analysis of the input data. It enables
	selecting 2 or 3 dimensions for the result space, selecting a set of the
	aggregators and few additional minor settings.

	\subsubsection{Dinemsions}
	2 or 3 dimensions can be defined. I the respective cases these are: page, row
	and column, or just row and column. Their interpretation is that all the values
	at a given coordinate, say in the given page, come from the input rows that fultil
	the dimension definition. Since the dimension is given by a pair: input column,
	value, fulfuling dimension definition means that the given input data row has
	a particular value in the column x, another particular value in the column y, etc.

	\subsubsection{Aggregations}
	The aggregations determine, how the values in the resulting table will be obtained.
	Usually many values from the input rows will be directed to a given cell (defined
	by a set of 2 or 3 coordinates). All the values are aggregated so the result may
	be obtained. The aggregation is defined by a source column index and the aggregator
	construction string. For the details on the aggregator construction strings see
	the manual section for the \texttt{aggr} library.

	\subsubsection{Extending dimensions with the aggregators}
	Based on the dimensions definitions and the input data, the particular coordinates
	are created and at each of the coordinates instances of all the requested aggregators
	are placed. This means that for every cell in the table defined by the dimension
	definitions, multiple results will be presented. This requires extending one of the
	output table's dimensions and by default the columns are extended, which is the
	most convenient solutions in most cases. If the extension of the rows dimension
	is required, an additional option: \texttt{-R} must be added to the command line
	which will alter the output accordingly.

	\subsubsection{Decorating the output table}
	Demending on the purpose the output table may or may not need to be described. If
	we expect further processing in the pipeline it may be more convenient to only
	print the values, whereas if the result is to be analyzed by a human, the row and
	the column captions should be added. By default the captions(headers) are not
	printed, but the behavior may be altered by adding an option: \texttt{-h} to the
	command line.

	\subsubsection{The input data header}
	The input data set may or may not contain an additional header row providing
	labels for the columns. Even though the input options (e.g. the dimension
	definitions) is always given by the column indices, the ouptut may be more
	readable if based on the original column captions (an aggregator may tor example
	be labeled "mean(result)" instead of "mean(4)". To indicate that the first input
	row should be interpreted as the header row providing the captions an option:
	\texttt{-H} must be added to the command line.

\end{document}
